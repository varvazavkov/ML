{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1292280d",
   "metadata": {},
   "source": [
    "# <font color = 'red'> ЛР 7. Метод главных компонент </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d08e816",
   "metadata": {},
   "source": [
    "Сложность: <font color = 'green'> Легко  </font>.\n",
    "\n",
    "Дата составления: 16.11.2023\n",
    "\n",
    "Срок выполнения: 1 неделя (с момента первой практики после выдачи).\n",
    "\n",
    "Автор: ст. преподаватель Кушнеров А.В."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb89937b",
   "metadata": {},
   "source": [
    "## <font color = 'green'> 1. Метод главных компонент.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5515a387-a409-4454-bd66-9b124d1bb04d",
   "metadata": {},
   "source": [
    "Метод главных компонент (PCA) - классический метод понижения размерности данных. \n",
    "\n",
    "Пусть задана матрица информации, содержащая векторы с информацией о данных. $$X=\\left(\n",
    "\\begin{array}{cccc}\n",
    " x_{1,1} & x_{1,2} & ... & x_{1,m} \\\\\n",
    " x_{2,1} & x_{2,2} & ... & x_{2,m} \\\\\n",
    " ... & ... & ... & ... \\\\\n",
    " x_{n,1} & x_{4,n} & ... & x_{n,m} \\\\\n",
    "\\end{array}\n",
    "\\right)$$\n",
    "\n",
    "Как видим рассматриваем $n$ сэмплов и $m$ фич (признаков). Задача **понижения размерности** заключается в преобразовании исходных данных, таким образом, чтобы исходная информации хранилась с использованием меньшего числа фич $k<n$ с сохранением её ценности. Этот метот относится к классу методов **обучения без учителя**, поэтому в нём отсутсвуют целевые метки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16445805-0022-44f0-b4b2-9f94235ebfe7",
   "metadata": {},
   "source": [
    "Для решения задачи введём некоторые обозначения. Пусть $Y = {y_{1},y_{2},...,y_{n}}$ выборка из генеральной совокупности. *Выборочное среднее* тогда записывается формулой $E(Y) = \\frac{1}{n}  \\sum\\limits_{j=1}^n y_{i} $. Вторая характеристика выборки это *выборочная дисперсия*. Несмещённая оценка дисперции записывается в виде: $D(Y) = \\frac{1}{n-1}  \\sum\\limits_{j=1}^n (y_{i} - E(y))^{2} $.\n",
    "\n",
    "Заметим, что в случае, если $Y$ - несмещена, то есть $E(Y) = 0$, тогда $D(Y) = \\frac{1}{n-1}  \\sum\\limits_{j=1}^n (y_{i})^{2}$. Если представить $Y$ в виде вектор столбца, то формулу дисперсии можно переписать в матричном виде: $D(\\overline{Y}) = \\frac{1}{n-1} \\overline{Y}^{T}\\overline{Y} $.\n",
    "\n",
    "Вернёмся к нашей задаче. Найдем вектор $\\overline{v}$, такой что при проекции данных на этот вектор, мы получим максимальную дисперсию. Этот вектор и будет первой новой компонентой, а полученные проекции сэмплов - координаты по новой компоненте.\n",
    "\n",
    "Одномерный вектор проекции $X\\overline{v}$ - тоже выборка, для которой мы можем посчитать дисперсию. Учитывая несмещённость данных получаем $D(X\\overline{v}) = \\frac{1}{n-1}(X\\overline{v})^{T}X\\overline{v} =  \\overline{v}^{T} \\frac{1}{n-1}X^{T}X\\overline{v} = \\overline{v}^{T} A \\overline{v}$. Обозначим $A=\\frac{1}{n-1}X^{T}X$. \n",
    "\n",
    "Далее получаем задачу оптимизации с условием. Для того, чтобы компонента была наиболее информативна, будем максимизировать дисперсию данных вдоль неё. Условием будет нормированность вектора $\\overline{v}$.\n",
    "\n",
    "$F(\\overline{v}) = \\overline{v}^{T} A \\overline{v}  -> max$ \n",
    "\n",
    "$\\overline{v}^{T}\\overline{v} =  1$\n",
    "\n",
    "Составим функцию Лагранжа $L(\\overline{v}) = \\overline{v}^{T} A \\overline{v} - \\lambda (\\overline{v}^{T}\\overline{v} - 1)$.\n",
    "\n",
    "Проверяем необходимое условие условного экстремума, используя матричные производные:  $L(\\overline{v})^{'} = ( A^{T}+A) \\overline{v} - 2\\lambda \\overline{v} = 0$. Учитывая симметричность матрицы $A$ получим итоговое соотношение для компоненты $\\overline{v} $. $$A\\overline{v}=\\lambda\\overline{v}.$$\n",
    "\n",
    "Полученное соотношение - это определение **собственного вектора** матрицы $A$. В качестве вектора главной компоненты возьмём один из них. А если учесть, что для полученного решения дисперсия $D(X\\overline{v})= \\overline{v}^{T} \\lambda \\overline{v} = \\lambda$ (где $\\lambda$ - собственное значение матрицы $A$), то максимальная дсиперсия будет достигаться вдоль собственного вектора, соответсвующего наибольшему собственному значению $A$.  Остальные компоненты также могут получены как собственные векторы, соответствующие собственным значениям в порядке убывания последних. \n",
    "\n",
    "\n",
    "Заметим, что полученная матрица $A$ - есть [матрица ковариации](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%B2%D0%B0%D1%80%D0%B8%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0) для $X$.\n",
    "\n",
    "Таким образом кратко алгоритм поиска новых компонент выглядит так:\n",
    "\n",
    "1. Центрируем числовые данные.\n",
    "2. Находим ковариационную матрицу.\n",
    "3. Находим её собственные векторы и упорядочиваем их по убываению их собственных значений.\n",
    "4. Выбираем нужное число компонент.\n",
    "5. Проецируем на них данные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3611d-517c-4acc-9a74-f85956fe0ee9",
   "metadata": {},
   "source": [
    "<font color = 'red' size = 5>Задание 1 </font>\n",
    "\n",
    "1. Реализуйте функцию для работы метода главных компонент методом собственных значений. \n",
    "2. Сравните результаты её работы со встроенной функцией на искусственных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f903aa-66f0-4ece-8001-6de5df4818a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font color = 'red' size = 5>Задание 2 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced712c-270c-4dba-b546-9067ecaaf461",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40a6b9-02fb-46a0-b341-63e2ee4c7ea9",
   "metadata": {},
   "source": [
    "1. Используя данные для цветков ириса произвести уменьшение размерности данных с помощью метода главных компонет. Реализовать собственный алгоритм, а также использовать встроенный.\n",
    "2. Оценить степень потери данных. \n",
    "3. Выберите оптимальное количество компонент в новых данных. \n",
    "4. Протестируйте точность различных алгоритмов классификации на исходном датасете и на преобразованном с помощью метода главных компонент. Дайте подробные выводы о различных комбинациях числа компонет и алгоритмах. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b17d38d-f38a-4681-bce2-4b47c0a6e728",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font color = 'red' size = 5>Задание 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831301c-a50a-4029-b270-1ac13235f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9b823-fc3c-4989-bc45-5894f580cb6d",
   "metadata": {},
   "source": [
    "1. Используя данные о рукописных цифрах произвести уменьшение размерности данных с помощью метода главных компонет.Реализовать собственный алгоритм, а также использовать встроенный.\n",
    "2. Оценить степень потери данных. \n",
    "3. Выберите оптимальное колиечество компонент в новых данных. \n",
    "4. Протестируйте точность различных алгоритмов классификации на исходном датасете и на преобразованном с помощью метода главных компонент. Дайте подробные выводы о различных комбинациях числа компонет и алгоритмах. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335bbc70-c750-4c53-8ead-57246a8666d1",
   "metadata": {},
   "source": [
    "<font color = 'red' size = 5>Задание 4 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdc7283-1d70-4d3f-a1f3-aa1e9f815af6",
   "metadata": {},
   "source": [
    "Вычислениями подвердите связь [сингулярного разложения матрицы](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%B8%D0%BD%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D0%B7%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5) с методом главных компонент. Приведите практический пример."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd02552-d2c6-47cd-be52-96d350545d26",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font color = 'red' size = 5>Задание 5 </font>\n",
    "\n",
    "1. Проверьте ваши навыки поиска новых компонент для любых данных из предыдущих ЛР. Можно ли оценить вклад исходных фич в новые компоненты?\n",
    "2. *Метод главных компонент не очень подходит для категориальных признаков. Предложите вариант корреляционного анализа и отбора таких признаков*.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f515b91-48c8-4209-938a-49faeec313b5",
   "metadata": {},
   "source": [
    "## Полезные ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940794f5-b9ee-4dcc-9d55-57029723f214",
   "metadata": {},
   "source": [
    "1. [Хорошая статья на русском о PCA](https://habr.com/ru/post/304214/)\n",
    "2. [sklearn PCA doc](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "3. [Выбор количества компонент](https://www.mikulskibartosz.name/pca-how-to-choose-the-number-of-components/)\n",
    "4. [PCA через сингулярное разложение](https://towardsdatascience.com/pca-and-svd-explained-with-numpy-5d13b0d2a4d8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
